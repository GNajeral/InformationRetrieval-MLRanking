{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Google file system\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "bM-QHyO_boT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63db55d0-34d2-4e54-c697-5c88e1455216"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From GIT HUB we implement the AdaRank algorithm. "
      ],
      "metadata": {
        "id": "Q5lq2W5ObBy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import sys\n",
        "import tabulate\n",
        "\n",
        "\n",
        "def group_counts(arr):\n",
        "    d = np.ones(arr.size, dtype=int)\n",
        "    d[1:] = (arr[:-1] != arr[1:]).astype(int)\n",
        "    return np.diff(np.where(np.append(d, 1))[0])\n",
        "\n",
        "\n",
        "def group_offsets(arr):\n",
        "    \"\"\"Return a sequence of start/end offsets for the value subgroups in the input\"\"\"\n",
        "    d = np.ones(arr.size, dtype=int)\n",
        "    d[1:] = (arr[:-1] != arr[1:]).astype(int)\n",
        "    idx = np.where(np.append(d, 1))[0]\n",
        "    return zip(idx, idx[1:])\n",
        "\n",
        "\n",
        "def load_docno(fname, letor=False):\n",
        "    \"\"\"Load docnos from the input in the SVMLight format\"\"\"\n",
        "    if letor:\n",
        "        docno_pattern = re.compile(r'#\\s*docid\\s*=\\s*(\\S+)')\n",
        "    else:\n",
        "        docno_pattern = re.compile(r'#\\s*(\\S+)')\n",
        "\n",
        "    docno = []\n",
        "    for line in open(fname):\n",
        "        if line.startswith('#'):\n",
        "            continue\n",
        "        m = re.search(docno_pattern, line)\n",
        "        if m is not None:\n",
        "            docno.append(m.group(1))\n",
        "    return np.array(docno)\n",
        "\n",
        "\n",
        "def print_ranking(qid, docno, pred, output=None):\n",
        "    table = []\n",
        "    headers = [\"qid\", \"docno\", \"rank\", \"score\"]\n",
        "    if output is None:\n",
        "        output = sys.stdout\n",
        "    for a, b in group_offsets(qid):\n",
        "        idx = np.argsort(-pred[a:b]) + a  # note the minus and plus a\n",
        "        for rank, i in enumerate(idx, 1):\n",
        "            table.append([qid[i], docno[i], rank, round(pred[i],3)])\n",
        "    output.write(tabulate.tabulate(table, headers, tablefmt=\"pretty\"))\n",
        "    \n",
        "    \n"
      ],
      "metadata": {
        "id": "1FIePZBLw-wv"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Scorer(object):\n",
        "    def __init__(self, score_func, **kwargs):\n",
        "        self.score_func = score_func\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def __call__(self, *args):\n",
        "        return self.score_func(*args, **self.kwargs)\n",
        "\n",
        "\n",
        "# Precision\n",
        "#\n",
        "def _p_score(y_true, y_pred, k=None):\n",
        "    order = np.argsort(-y_pred)\n",
        "    y_true = np.take(y_true, order[:k])\n",
        "    return np.sum(y_true > 0) / len(y_true)\n",
        "\n",
        "\n",
        "def p_score(y_true, y_pred, qid, k=None):\n",
        "    return np.array([_p_score(y_true[a:b], y_pred[a:b], k=k) for a, b in group_offsets(qid)])\n",
        "\n",
        "\n",
        "class PScorer(Scorer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(PScorer, self).__init__(_p_score, **kwargs)\n",
        "\n",
        "\n",
        "# AP (Average Precision)\n",
        "#\n",
        "def _ap_score(y_true, y_pred):\n",
        "    order = np.argsort(-y_pred)\n",
        "    y_true = np.take(y_true, order)\n",
        "    pos = 1 + np.where(y_true > 0)[0]\n",
        "    n_rels = 1 + np.arange(len(pos))\n",
        "    return np.mean(n_rels / pos) if len(pos) > 0 else 0\n",
        "\n",
        "\n",
        "def ap_score(y_true, y_pred, qid):\n",
        "    return np.array([_ap_score(y_true[a:b], y_pred[a:b]) for a, b in group_offsets(qid)])\n",
        "\n",
        "\n",
        "class APScorer(Scorer):\n",
        "    def __init__(self):\n",
        "        super(APScorer, self).__init__(_ap_score)\n",
        "\n",
        "\n",
        "# DCG/nDCG (Normalized Discounted Cumulative Gain)\n",
        "#\n",
        "def _burges_dcg(y_true, y_pred, k=None):\n",
        "    # order = np.argsort(y_pred)[::-1]\n",
        "    order = np.argsort(-y_pred)\n",
        "    y_true = np.take(y_true, order[:k])\n",
        "    gain = 2 ** y_true - 1\n",
        "    discounts = np.log2(np.arange(len(gain)) + 2)\n",
        "    return np.sum(gain / discounts)\n",
        "\n",
        "\n",
        "def _trec_dcg(y_true, y_pred, k=None):\n",
        "    order = np.argsort(-y_pred)\n",
        "    y_true = np.take(y_true, order[:k])\n",
        "    gain = y_true\n",
        "    discounts = np.log2(np.arange(len(gain)) + 2)\n",
        "    return np.sum(gain / discounts)\n",
        "\n",
        "\n",
        "def _dcg_score(y_true, y_pred, qid, k=None, dcg_func=None):\n",
        "    assert dcg_func is not None\n",
        "    y_true = np.maximum(y_true, 0)\n",
        "    return np.array([dcg_func(y_true[a:b], y_pred[a:b], k=k) for a, b in group_offsets(qid)])\n",
        "\n",
        "\n",
        "def _ndcg_score(y_true, y_pred, qid, k=None, dcg_func=None):\n",
        "    assert dcg_func is not None\n",
        "    y_true = np.maximum(y_true, 0)\n",
        "    dcg = _dcg_score(y_true, y_pred, qid, k=k, dcg_func=dcg_func)\n",
        "    idcg = np.array([dcg_func(np.sort(y_true[a:b]), np.arange(0, b - a), k=k)\n",
        "                     for a, b in group_offsets(qid)])\n",
        "    assert (dcg <= idcg).all()\n",
        "    idcg[idcg == 0] = 1\n",
        "    return dcg / idcg\n",
        "\n",
        "\n",
        "def ndcg_score(y_true, y_pred, qid, k=None, version='burges'):\n",
        "    assert version in ['burges', 'trec']\n",
        "    dcg_func = _burges_dcg if version == 'burges' else _trec_dcg\n",
        "    return _ndcg_score(y_true, y_pred, qid, k=k, dcg_func=dcg_func)\n",
        "\n",
        "\n",
        "\n",
        "class NDCGScorer(Scorer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(NDCGScorer, self).__init__(ndcg_score, **kwargs)\n",
        "\n"
      ],
      "metadata": {
        "id": "QQ6i_sDnbcSU"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "AdaRank algorithm\n",
        "\"\"\"\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import sys\n",
        "\n",
        "from sklearn.utils import check_X_y\n",
        "\n",
        "\n",
        "\n",
        "class AdaRank(sklearn.base.BaseEstimator):\n",
        "    \"\"\"AdaRank algorithm\"\"\"\n",
        "\n",
        "    def __init__(self, max_iter=500, tol=0.0001, estop=1, verbose=False, scorer=None):\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.estop = estop\n",
        "        self.verbose = verbose\n",
        "        self.scorer = scorer\n",
        "\n",
        "    def fit(self, X, y, qid, X_valid=None, y_valid=None, qid_valid=None):\n",
        "        \"\"\"Fit a model to the data\"\"\"\n",
        "        X, y = check_X_y(X, y, 'csr')\n",
        "        X = X.toarray()\n",
        "\n",
        "        if X_valid is None:\n",
        "            X_valid, y_valid, qid_valid = X, y, qid\n",
        "        else:\n",
        "            X_valid, y_valid = check_X_y(X_valid, y_valid, 'csr')\n",
        "            X_valid = X_valid.toarray()\n",
        "\n",
        "        n_queries = np.unique(qid).shape[0]\n",
        "        weights = np.ones(n_queries, dtype=np.float64) / n_queries\n",
        "        weak_rankers = []\n",
        "        coef = np.zeros(X.shape[1])\n",
        "\n",
        "        # use nDCG@10 as the default scorer\n",
        "        if self.scorer is None:\n",
        "            self.scorer = NDCGScorer(k=10)\n",
        "\n",
        "        # precompute performance measurements for all weak rankers\n",
        "        weak_ranker_score = []\n",
        "        for j in range(X.shape[1]):\n",
        "            pred = X[:, j].ravel()\n",
        "            weak_ranker_score.append(self.scorer(y, pred, qid))\n",
        "\n",
        "        best_perf_train = -np.inf\n",
        "        best_perf_valid = -np.inf\n",
        "        used_fids = []\n",
        "        estop = None\n",
        "\n",
        "        self.n_iter = 0\n",
        "        while self.n_iter < self.max_iter:\n",
        "            self.n_iter += 1\n",
        "\n",
        "            best_weighted_average = -np.inf\n",
        "            best_weak_ranker = None\n",
        "            for fid, score in enumerate(weak_ranker_score):\n",
        "                if fid in used_fids:\n",
        "                    continue\n",
        "                weighted_average = np.dot(weights, score)\n",
        "                if weighted_average > best_weighted_average:\n",
        "                    best_weak_ranker = {'fid': fid, 'score': score}\n",
        "                    best_weighted_average = weighted_average\n",
        "\n",
        "            # stop when all the weaker rankers are out\n",
        "            if best_weak_ranker is None:\n",
        "                break\n",
        "\n",
        "            h = best_weak_ranker\n",
        "            h['alpha'] = 0.5 * (math.log(np.dot(weights, 1 + h['score']) /\n",
        "                                         np.dot(weights, 1 - h['score'])))\n",
        "            weak_rankers.append(h)\n",
        "\n",
        "            # update the ranker\n",
        "            coef[h['fid']] += h['alpha']\n",
        "\n",
        "            # if len(used_fids) > 5:\n",
        "            #     used_fids.pop(0)\n",
        "            # used_fids.append(h['fid'])\n",
        "\n",
        "            # score both training and validation data\n",
        "            score_train = self.scorer(y, np.dot(X, coef), qid)\n",
        "            perf_train = score_train.mean()\n",
        "\n",
        "            perf_valid = perf_train\n",
        "            if X_valid is not X:\n",
        "                perf_valid = self.scorer(y_valid, np.dot(X_valid, coef), qid_valid).mean()\n",
        "\n",
        "            if self.verbose:\n",
        "                print('{n_iter}\\t{alpha}\\t{fid}\\t{score}\\ttrain {train:.4f}\\tvalid {valid:.4f}'.\n",
        "                      format(n_iter=self.n_iter, alpha=h['alpha'], fid=h['fid'],\n",
        "                             score=h['score'][:5], train=perf_train, valid=perf_valid),\n",
        "                      file=sys.stderr)\n",
        "\n",
        "            # update the best validation scores\n",
        "            if perf_valid > best_perf_valid + self.tol:\n",
        "                estop = 0\n",
        "                best_perf_valid = perf_valid\n",
        "                self.coef_ = coef.copy()\n",
        "            else:\n",
        "                estop += 1\n",
        "\n",
        "            # update the best training score\n",
        "            if perf_train > best_perf_train + self.tol:\n",
        "                best_perf_train = perf_train\n",
        "            else:\n",
        "                # stop if scores on both sets fail to improve\n",
        "                if estop >= self.estop:\n",
        "                    break\n",
        "\n",
        "            # update weights\n",
        "            new_weights = np.exp(-score_train)\n",
        "            weights = new_weights / new_weights.sum()\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X, qid):\n",
        "        \"\"\"Make predictions\"\"\"\n",
        "        return np.dot(X.toarray(), self.coef_)\n"
      ],
      "metadata": {
        "id": "Gzs4TgsHbcXF"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model implementation for our dataset."
      ],
      "metadata": {
        "id": "1TsLk4QPb_oQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import of the necessary libraries"
      ],
      "metadata": {
        "id": "8DQ8j777fl44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.datasets import dump_svmlight_file, load_svmlight_file\n",
        "import re\n",
        "import nltk\n",
        "from nltk import PorterStemmer, WordNetLemmatizer\n",
        "import string as st\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "PZnMwy4cfdhB"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FIRST MODEL - ORIGINAL DATASET**"
      ],
      "metadata": {
        "id": "x_rrvrEtf8uS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We obtain the data set that we are going to use for the development of the model. "
      ],
      "metadata": {
        "id": "xcigmvarcO1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sheets_dict = pd.read_excel(\"/gdrive/My Drive/MASTER/INFO.BIOMÉDICA/loinc_dataset_labels-v2.xlsx\", sheet_name=None, skiprows=1, header=1)\n",
        "all_sheets = []\n",
        "for name, sheet in sheets_dict.items():\n",
        "    all_sheets.append(sheet)\n",
        "    df= pd.concat(all_sheets)\n",
        "    df.reset_index(inplace=True, drop=True)"
      ],
      "metadata": {
        "id": "1bvqcyVQQF3P"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download of \n",
        " - Natural Language ToolKit - allows the developmnet of the AdaRank model. "
      ],
      "metadata": {
        "id": "kfxHWGjTcmpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xrlvTzfebzK",
        "outputId": "dd208d08-3bfc-453d-ebe8-56f9c4485fc2"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to carry out the AdaRank algorithm the first thing we do is to download the \"stopwords\" and \"wordnet\" that is implemented in nltk. \n",
        "\n",
        "As a series of errors can appear what we do is to implement a \"try/except\" to be able to download everything correctl"
      ],
      "metadata": {
        "id": "nz4vuuk-c8ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0u2oGDddHyC",
        "outputId": "787dbf43-a3da-4512-b8b8-63456a85ea65"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next thing we do is to clear the text (column long_common name) to be able to insert it in the model. \n"
      ],
      "metadata": {
        "id": "yHU-zIG3eSiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing we want to do is to remove the punctuation marks, for this we use string.punctuation imported earlier, which contains all the punctuation symbols.  \n",
        "We generate a function to be able to apply it later on the data (we will do this with all the elements necessary for the cleaning of the text). "
      ],
      "metadata": {
        "id": "DQgeKK74feeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punct(text):\n",
        "    return (\"\".join([ch for ch in text if ch not in st.punctuation]))"
      ],
      "metadata": {
        "id": "bxMGAR5pfHSO"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to tokenize each of the words in each document in order to enter them into the model."
      ],
      "metadata": {
        "id": "oyWs0cP6nfkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    text = re.split('\\s+' ,text)\n",
        "    return [x.lower() for x in text]"
      ],
      "metadata": {
        "id": "cZ5a3J_ggh5g"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removal of all tokens with lengths less than 3 as we assume that they are not sufficiently relevant for training the model."
      ],
      "metadata": {
        "id": "DGnHCdA9ns1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_small_words(text):\n",
        "    return [x for x in text if len(x) > 3 ]"
      ],
      "metadata": {
        "id": "ZNcFCc79nsM1"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removal of all elements called \"stopwords\" (articles, prepositions, pronouns, etc). To do this we set the language to English, as this is the language in which we have our data. \n",
        "\n",
        "It is done by using NLTK corpus stopwords list to match. "
      ],
      "metadata": {
        "id": "mCMVSAz5n6uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "    return [word for word in text if word not in nltk.corpus.stopwords.words('english')]"
      ],
      "metadata": {
        "id": "xkdGOtgknsVj"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using NLTK's PorterStemmer() we can keep the root words by removing the morphological suffixes and prefixes. "
      ],
      "metadata": {
        "id": "i5dHDkCWojW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming(text):\n",
        "    ps = PorterStemmer()\n",
        "    return [ps.stem(word) for word in text]"
      ],
      "metadata": {
        "id": "vVWaJbM4nsYH"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using WordNetLemmatizer, again a module of NLTK, we can carry out the \"lemmatization\" of the words that remain in the text of each of the documents. \n",
        "\n",
        "In this way, we obtain all those words that have a semantic relationship with each other. "
      ],
      "metadata": {
        "id": "mD8WjHc9o30d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize(text):\n",
        "    word_net = WordNetLemmatizer()\n",
        "    return [word_net.lemmatize(word) for word in text]"
      ],
      "metadata": {
        "id": "bKRO0SIioiku"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally for each of the words that are in token form we join them together, generating a whole sentence in token form. "
      ],
      "metadata": {
        "id": "-ySReCBKps0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def return_sentences(tokens):\n",
        "    return \" \".join([word for word in tokens])"
      ],
      "metadata": {
        "id": "jz4xih5Ept2m"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For all the documents that we have in our DataFrame we have to apply each of these steps, so, in order to simplify the code we generate a function that implements all of them."
      ],
      "metadata": {
        "id": "akEyUeK6o-T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    return return_sentences(\n",
        "    lemmatize(stemming (remove_stopwords(remove_small_words(\n",
        "                   (tokenize(remove_punct(text))))))))"
      ],
      "metadata": {
        "id": "yxXTyuBJp3uc"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert documents to feature vectors. "
      ],
      "metadata": {
        "id": "179xStMQf9v8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "df['clean_text'] = df['long_common_name'].apply(lambda x: preprocess_text(x))\n",
        "print(df['clean_text'])\n",
        "X = tfidf.fit_transform(df['clean_text']).toarray()"
      ],
      "metadata": {
        "id": "p8Y11eFFqGiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "463bb98b-86d0-456e-ca4e-b45eb875b8df"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                 reactiv protein massvolum serum plasma\n",
            "1                              bicarbon molesvolum blood\n",
            "2                                             type blood\n",
            "3                    trimethoprimsulfamethoxazol suscept\n",
            "4                    bilirubintot massvolum serum plasma\n",
            "                             ...                        \n",
            "196                                  monocyt volum blood\n",
            "197                           major crossmatch interpret\n",
            "198                                   ampicillin suscept\n",
            "199    alanin aminotransferas enzymat activityvolum s...\n",
            "200                          ampicillinsulbactam suscept\n",
            "Name: clean_text, Length: 201, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We check how correctly a new column has been added in which we have the text completely processed.\n"
      ],
      "metadata": {
        "id": "-7SLyjQTO_kB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(\"long. X:\", len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eStWcWWGqOM1",
        "outputId": "71ab77d4-af9e-4100-dc9b-060f142cf887"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.43361229 0.57014337 0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "long. X: 201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see what we get is an array with a length of 201 elements (as many as rows as the DataFrame has) in the form of tokens."
      ],
      "metadata": {
        "id": "uOqDoF2BPFmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We add a new column called features, in which we have the previous vectorization. (Each document has its own vectorization).  \n",
        "\n",
        "In addition, we define the train (70%) and test (30%)  sets."
      ],
      "metadata": {
        "id": "YweiGvLjqolF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['features'] = X.tolist()\n",
        "\n",
        "#Get train and test set\n",
        "df = df.sample(frac=1, random_state = 2)\n",
        "train_size = int(0.7 * len(df))\n",
        "train_set = df[:train_size].sort_values(by=['qid'])\n",
        "test_set = df[train_size:].sort_values(by=['qid'])"
      ],
      "metadata": {
        "id": "cWhx9aKjqnW1"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next thing we will do is to convert the DataFrame to a numpy array and differ from X features and Y labels. \n"
      ],
      "metadata": {
        "id": "lQmFg-ULrqVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame to numpy array\n",
        "qid = df['qid'].to_numpy()\n",
        "y = df['Label'].to_numpy()\n",
        "X_train = np.array(train_set['features'].values.tolist())\n",
        "qid_train = train_set['qid'].to_numpy()\n",
        "y_train = train_set['Label'].to_numpy()\n",
        "X_test = np.array(test_set['features'].values.tolist())\n",
        "qid_test = test_set['qid'].to_numpy()\n",
        "y_test = test_set['Label'].to_numpy()"
      ],
      "metadata": {
        "id": "tlw1rlVNrkCu"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We converted the arrays created just before into \"svmlight\" format documents, because the implemented AdaRank model uses this type of files. \n",
        "\n",
        "In addition, we add a document number to each of the documents in our data in order to identify them. So, all those that do not have a document number are deleted. \n",
        "- We do this in order to later obtain an adequate ranking of the prediction made by the model, being able to obtain the number of documents located in each position. \n",
        "- To simplify the code we use the following function."
      ],
      "metadata": {
        "id": "3quSa8DAsaf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_docnos(docnos, file, train_docnos, train_file, test_docnos, test_file):\n",
        "    if file == 'loinc_dataset-v2_without_docnos.dat':\n",
        "        out_file = 'loinc_dataset-v2.dat'\n",
        "        out_train_file = 'train_loinc_dataset-v2.dat'\n",
        "        out_test_file = 'test_loinc_dataset-v2.dat'\n",
        "    else:\n",
        "        out_file = 'extended_loinc_dataset-v2.dat'\n",
        "        out_train_file = 'extended_train_loinc_dataset-v2.dat'\n",
        "        out_test_file = 'extended_test_loinc_dataset-v2.dat'\n",
        "        \n",
        "    in_files = [file, train_file, test_file]\n",
        "    out_files = [out_file, out_train_file, out_test_file]\n",
        "    \n",
        "    for i in range(3):\n",
        "        if i == 0:\n",
        "            data = docnos\n",
        "        elif i == 1:\n",
        "            data = train_docnos\n",
        "        else:\n",
        "            data = test_docnos\n",
        "        \n",
        "        with open(in_files[i]) as fin, open(out_files[i], 'w') as fout:\n",
        "                index = 0\n",
        "                for line in fin:\n",
        "                    fout.write(line.replace('\\n', ' ' + str(data[index]) + '\\n'))\n",
        "                    index += 1\n",
        "    return out_file, out_train_file, out_test_file"
      ],
      "metadata": {
        "id": "3kWWNQy4kqyB"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_svmlight_files(df, X, y, X_train, y_train, X_test, y_test):\n",
        "    if len(df) == 201: #201 is the length of our original loinc dataset \n",
        "        file = 'loinc_dataset-v2_without_doc_numb.dat'\n",
        "        train_file = 'train_loinc_dataset-v2_without_doc_numb.dat'\n",
        "        test_file = 'test_loinc_dataset-v2_without_doc_numb.dat'\n",
        "    else:\n",
        "        file = 'extended_loinc_dataset-v2_without_doc_numb.dat'\n",
        "        train_file = 'extended_train_loinc_dataset-v2_without_doc_numb.dat'\n",
        "        test_file = 'extended_test_loinc_dataset-v2_without_doc_numb.dat'\n",
        "  \n",
        "  \n",
        "    # Numpy arrays into svmlight files\n",
        "    dump_svmlight_file(X, y, file, query_id=qid)\n",
        "    dump_svmlight_file(X_train, y_train, train_file, query_id=qid_train)\n",
        "    dump_svmlight_file(X_test, y_test, test_file, query_id=qid_test)\n",
        "    \n",
        "    # Add docnos to svmlight files\n",
        "    out_file, out_train_file, out_test_file = add_docnos(df['doc_numb'].tolist(), file, train_set['doc_numb'].tolist()\n",
        "                                                         , train_file, test_set['doc_numb'].tolist(), test_file)\n",
        "    \n",
        "    # Remove files without docnos\n",
        "    my_dir = os.getcwd()\n",
        "    for fname in os.listdir(my_dir):\n",
        "        if 'docnos' in fname :\n",
        "            os.remove(os.path.join(my_dir, fname))\n",
        "    return out_file, out_train_file, out_test_file"
      ],
      "metadata": {
        "id": "2RtCm3S8Jl1A"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file, train_file, test_file  = df_to_svmlight_files(df, X, y, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "OfBwAImOtFQc"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have preprocessed all the text and have it in the proper format we perform the AdaRank algorithm. "
      ],
      "metadata": {
        "id": "nP_ASWGQt1lr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos cada uno de los conjuntos de train y test\n",
        "Redifine train and test set in the svmlight files obtained."
      ],
      "metadata": {
        "id": "3-82TGJDuhQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, qid_train = load_svmlight_file(train_file, query_id=True)\n",
        "X_test, y_test, qid_test = load_svmlight_file(test_file, query_id=True)"
      ],
      "metadata": {
        "id": "au83bO6HudNU"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of the AdaRank algorithm:\n",
        "- Maximum iterations: 100\n",
        "- Stop = 10 \n",
        "- Scorer = NDCG with K = 20.\n",
        "\n",
        "We use Normalized Discounted Cumulative Gain as the score function because it is a quality ranking measure that is used to measure the effectiveness of different algorithms. \n",
        "\n",
        "AdaRank is implemented for 100 iterations where NDCG@20 is optimized. When no improvement is made in the previous 10 iterations the algorithm stops.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vuYNK0Dvur2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AdaRank(max_iter=100, estop=10, scorer=NDCGScorer(k=5)).fit(X_train, y_train, qid_train)"
      ],
      "metadata": {
        "id": "UZ8CC0YZupmE"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicción del modelo utilizando el conjunto de test."
      ],
      "metadata": {
        "id": "o3-FBK5UvMQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test, qid_test)"
      ],
      "metadata": {
        "id": "Mpz0Bp7HvMYe"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos los resultados del score de NDCG."
      ],
      "metadata": {
        "id": "JM-FO1rLvUkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in (1, 2, 3, 4, 5, 10, 20, 40):\n",
        "    score = NDCGScorer(k=k)(y_test, pred, qid_test).mean()\n",
        "    print('nDCG@{}\\t{}'.format(k, score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyyRRbEivUOz",
        "outputId": "a2b66b44-2fee-4380-c722-50f92b3e20ce"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nDCG@1\t0.6666666666666666\n",
            "nDCG@2\t0.4797939499646728\n",
            "nDCG@3\t0.446458651520288\n",
            "nDCG@4\t0.446458651520288\n",
            "nDCG@5\t0.446458651520288\n",
            "nDCG@10\t0.519261130459676\n",
            "nDCG@20\t0.5601962312253753\n",
            "nDCG@40\t0.5601962312253753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also implement AP_score and precison score. "
      ],
      "metadata": {
        "id": "rClANl7jlrnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ap_score = APScorer()(y_test, pred)\n",
        "print(\"ap_score:\", ap_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr2CCHhwbqsI",
        "outputId": "b7f9da72-ef62-455b-9071-6684db8e1919"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ap_score: 0.3400857326242435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to calculate the precision metric we round the decimal numbers of the predictions obtained to their nearest whole number without decimal places. "
      ],
      "metadata": {
        "id": "eycB3hx9CzbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "round_pred = np.round(pred, decimals = 0)"
      ],
      "metadata": {
        "id": "KcPMvDRiCWPr"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prec_score = PScorer()(y_test, round_pred)\n",
        "print(\"precision score:\", prec_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYbg8ALSdXy3",
        "outputId": "5b943b35-f92e-4920-9886-581826c49d35"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision score: 0.08196721311475409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We obtain the ranking of the documents in the test set. "
      ],
      "metadata": {
        "id": "kh_ncw_pvgDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the load_docno function already implemented, which returns the document number of each of the documents that make up the test set."
      ],
      "metadata": {
        "id": "fAauKOICXhmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docno = load_docno(test_file, letor=False)"
      ],
      "metadata": {
        "id": "WE8rdnQvXXTW"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the print_ranking function we obtain the ranking of each of the documents in the test set, as well as the score given to each of them."
      ],
      "metadata": {
        "id": "XnSoH0-LYJ82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_ranking(qid_test, docno, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6lU8PZSX2CC",
        "outputId": "273c0700-70c9-4aa0-b037-c1e854be30bd"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+------+-------+\n",
            "| qid | docno | rank | score |\n",
            "+-----+-------+------+-------+\n",
            "|  1  |  23   |  1   | 1.121 |\n",
            "|  1  |  53   |  2   | 0.976 |\n",
            "|  1  |   5   |  3   | 0.819 |\n",
            "|  1  |  27   |  4   | 0.328 |\n",
            "|  1  |  33   |  5   | 0.304 |\n",
            "|  1  |  50   |  6   | 0.281 |\n",
            "|  1  |  39   |  7   | 0.224 |\n",
            "|  1  |  47   |  8   | 0.217 |\n",
            "|  1  |  59   |  9   | 0.203 |\n",
            "|  1  |  16   |  10  | 0.196 |\n",
            "|  1  |  44   |  11  | 0.155 |\n",
            "|  1  |  32   |  12  | 0.145 |\n",
            "|  1  |   8   |  13  |  0.0  |\n",
            "|  1  |  34   |  14  |  0.0  |\n",
            "|  1  |  52   |  15  |  0.0  |\n",
            "|  1  |  64   |  16  |  0.0  |\n",
            "|  1  |  40   |  17  |  0.0  |\n",
            "|  1  |  48   |  18  |  0.0  |\n",
            "|  1  |  51   |  19  |  0.0  |\n",
            "|  1  |  38   |  20  |  0.0  |\n",
            "|  2  |  17   |  1   | 0.328 |\n",
            "|  2  |  38   |  2   | 0.304 |\n",
            "|  2  |  37   |  3   | 0.304 |\n",
            "|  2  |  36   |  4   | 0.303 |\n",
            "|  2  |  30   |  5   | 0.303 |\n",
            "|  2  |  14   |  6   | 0.246 |\n",
            "|  2  |  39   |  7   | 0.229 |\n",
            "|  2  |  10   |  8   | 0.222 |\n",
            "|  2  |  44   |  9   | 0.212 |\n",
            "|  2  |   6   |  10  | 0.202 |\n",
            "|  2  |   7   |  11  | 0.186 |\n",
            "|  2  |   1   |  12  |  0.0  |\n",
            "|  2  |  29   |  13  |  0.0  |\n",
            "|  2  |  41   |  14  |  0.0  |\n",
            "|  2  |  55   |  15  |  0.0  |\n",
            "|  2  |  58   |  16  |  0.0  |\n",
            "|  2  |  22   |  17  |  0.0  |\n",
            "|  2  |  66   |  18  |  0.0  |\n",
            "|  2  |  50   |  19  |  0.0  |\n",
            "|  2  |   3   |  20  |  0.0  |\n",
            "|  2  |  51   |  21  |  0.0  |\n",
            "|  2  |   9   |  22  |  0.0  |\n",
            "|  3  |  15   |  1   | 1.121 |\n",
            "|  3  |   3   |  2   | 0.328 |\n",
            "|  3  |  37   |  3   | 0.304 |\n",
            "|  3  |  51   |  4   | 0.281 |\n",
            "|  3  |  35   |  5   | 0.203 |\n",
            "|  3  |  66   |  6   | 0.196 |\n",
            "|  3  |  57   |  7   | 0.155 |\n",
            "|  3  |  54   |  8   | 0.145 |\n",
            "|  3  |  53   |  9   |  0.0  |\n",
            "|  3  |   5   |  10  |  0.0  |\n",
            "|  3  |  62   |  11  |  0.0  |\n",
            "|  3  |  44   |  12  |  0.0  |\n",
            "|  3  |  23   |  13  |  0.0  |\n",
            "|  3  |  12   |  14  |  0.0  |\n",
            "|  3  |  17   |  15  |  0.0  |\n",
            "|  3  |  63   |  16  |  0.0  |\n",
            "|  3  |  21   |  17  |  0.0  |\n",
            "|  3  |  34   |  18  |  0.0  |\n",
            "|  3  |  29   |  19  |  0.0  |\n",
            "+-----+-------+------+-------+"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FIRST MODEL - ORIGINAL DATASET**"
      ],
      "metadata": {
        "id": "jecoCzMcl_BT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We follow the same steps as above for this new dataset "
      ],
      "metadata": {
        "id": "nq_H9ThjSSt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sheets_dict = pd.read_excel(\"/gdrive/My Drive/MASTER/INFO.BIOMÉDICA/extended_loinc_dataset-v2.xlsx\", sheet_name=None, skiprows=1, header=1)\n",
        "all_sheets = []\n",
        "for name, sheet in sheets_dict.items():\n",
        "    all_sheets.append(sheet)\n",
        "    df_ext= pd.concat(all_sheets)\n",
        "    df_ext.reset_index(inplace=True, drop=True)"
      ],
      "metadata": {
        "id": "_NLc_imzSU2A"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "df_ext['clean_text'] = df_ext['long_common_name'].apply(lambda x: preprocess_text(x))\n",
        "print(df_ext['clean_text'])\n",
        "X = tfidf.fit_transform(df_ext['clean_text']).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzWW6cb-T0W6",
        "outputId": "20c39e7d-461d-4f3d-e66a-776d078664ce"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                 reactiv protein massvolum serum plasma\n",
            "1                              bicarbon molesvolum blood\n",
            "2                                             type blood\n",
            "3                    trimethoprimsulfamethoxazol suscept\n",
            "4                    bilirubintot massvolum serum plasma\n",
            "                             ...                        \n",
            "595                       caroten massvolum serum plasma\n",
            "596    hepat viru gene mutat detect identifi genotyp ...\n",
            "597                     lutropin unitsvolum serum plasma\n",
            "598              25hydroxyvitamin massvolum serum plasma\n",
            "599                                   zinc massmass hair\n",
            "Name: clean_text, Length: 600, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(\"long. X:\", len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y40oXL6-T4zG",
        "outputId": "27ac7574-6c3e-42a9-93a9-2084f4288f5f"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.85637899 0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.57735027]]\n",
            "long. X: 600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext['features'] = X.tolist()\n",
        "\n",
        "#Get train and test set\n",
        "df_ext= df_ext.sample(frac=1, random_state = 2)\n",
        "train_size = int(0.7 * len(df_ext))\n",
        "train_set = df_ext[:train_size].sort_values(by=['qid'])\n",
        "test_set = df_ext[train_size:].sort_values(by=['qid'])"
      ],
      "metadata": {
        "id": "Hhs0PfeQT7eq"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame to numpy array\n",
        "qid = df_ext['qid'].to_numpy()\n",
        "y = df_ext['Label'].to_numpy()\n",
        "X_train = np.array(train_set['features'].values.tolist())\n",
        "qid_train = train_set['qid'].to_numpy()\n",
        "y_train = train_set['Label'].to_numpy()\n",
        "X_test = np.array(test_set['features'].values.tolist())\n",
        "qid_test = test_set['qid'].to_numpy()\n",
        "y_test = test_set['Label'].to_numpy()"
      ],
      "metadata": {
        "id": "BHYcBbqPT-iJ"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file, train_file, test_file  = df_to_svmlight_files(df_ext, X, y, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "Z0seB7ibUCJc"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_file = 'ranking_extended.txt'\n",
        "X_train, y_train, qid_train = load_svmlight_file(train_file, query_id=True)\n",
        "X_test, y_test, qid_test = load_svmlight_file(test_file, query_id=True)"
      ],
      "metadata": {
        "id": "_lIsNvNnUEuF"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AdaRank(max_iter=100, estop=10, scorer=NDCGScorer(k=5)).fit(X_train, y_train, qid_train)"
      ],
      "metadata": {
        "id": "eUNE2fLeVyaH"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test, qid_test)"
      ],
      "metadata": {
        "id": "HGmOLN8wV0rB"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in (1, 2, 3, 4, 5, 10, 20, 40):\n",
        "    score = NDCGScorer(k=k)(y_test, pred, qid_test).mean()\n",
        "    print('nDCG@{}\\t{}'.format(k, score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xnWXjaiV3hD",
        "outputId": "05e10ca2-9454-4f7d-d72b-11bcc300f50f"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nDCG@1\t0.0\n",
            "nDCG@2\t0.0\n",
            "nDCG@3\t0.0\n",
            "nDCG@4\t0.08802270752419696\n",
            "nDCG@5\t0.15249817539662058\n",
            "nDCG@10\t0.24650686715920522\n",
            "nDCG@20\t0.25682062871869804\n",
            "nDCG@40\t0.33714155969496207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docno = load_docno(test_file, letor=False)"
      ],
      "metadata": {
        "id": "hDXKV2puYe-2"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_ranking(qid_test, docno, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHJT4_BAYyEW",
        "outputId": "bb733d94-83f0-4ded-af6b-0c46b45e03ea"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+------+-------+\n",
            "| qid | docno | rank | score |\n",
            "+-----+-------+------+-------+\n",
            "|  1  |  62   |  1   | 0.757 |\n",
            "|  1  |  48   |  2   | 0.611 |\n",
            "|  1  |  23   |  3   | 0.597 |\n",
            "|  1  |  57   |  4   | 0.551 |\n",
            "|  1  |  51   |  5   | 0.476 |\n",
            "|  1  |  10   |  6   | 0.061 |\n",
            "|  1  |  50   |  7   | 0.058 |\n",
            "|  1  |  22   |  8   | 0.058 |\n",
            "|  1  |   9   |  9   | 0.058 |\n",
            "|  1  |   1   |  10  | 0.051 |\n",
            "|  1  |  60   |  11  | 0.05  |\n",
            "|  1  |  47   |  12  | 0.044 |\n",
            "|  1  |  59   |  13  | 0.041 |\n",
            "|  1  |  44   |  14  | 0.032 |\n",
            "|  1  |  32   |  15  | 0.029 |\n",
            "|  1  |  46   |  16  | 0.025 |\n",
            "|  1  |  52   |  17  |  0.0  |\n",
            "|  1  |  35   |  18  |  0.0  |\n",
            "|  1  |  37   |  19  |  0.0  |\n",
            "|  1  |  49   |  20  |  0.0  |\n",
            "|  1  |  27   |  21  |  0.0  |\n",
            "|  1  |  20   |  22  |  0.0  |\n",
            "|  1  |  64   |  23  |  0.0  |\n",
            "|  2  |  24   |  1   | 0.757 |\n",
            "|  2  |  23   |  2   | 0.611 |\n",
            "|  2  |  31   |  3   | 0.596 |\n",
            "|  2  |   1   |  4   | 0.429 |\n",
            "|  2  |  15   |  5   | 0.07  |\n",
            "|  2  |  59   |  6   | 0.061 |\n",
            "|  2  |  35   |  7   | 0.058 |\n",
            "|  2  |  49   |  8   | 0.048 |\n",
            "|  2  |  52   |  9   | 0.044 |\n",
            "|  2  |  63   |  10  | 0.039 |\n",
            "|  2  |  47   |  11  | 0.034 |\n",
            "|  2  |  12   |  12  | 0.032 |\n",
            "|  2  |  21   |  13  |  0.0  |\n",
            "|  2  |  48   |  14  |  0.0  |\n",
            "|  2  |  11   |  15  |  0.0  |\n",
            "|  3  |  58   |  1   | 0.663 |\n",
            "|  3  |  25   |  2   | 0.459 |\n",
            "|  3  |   2   |  3   | 0.43  |\n",
            "|  3  |  19   |  4   | 0.422 |\n",
            "|  3  |  39   |  5   | 0.317 |\n",
            "|  3  |  20   |  6   | 0.07  |\n",
            "|  3  |  43   |  7   | 0.064 |\n",
            "|  3  |  46   |  8   | 0.051 |\n",
            "|  3  |  35   |  9   | 0.041 |\n",
            "|  3  |   7   |  10  | 0.039 |\n",
            "|  3  |  50   |  11  |  0.0  |\n",
            "|  3  |   8   |  12  |  0.0  |\n",
            "|  3  |  12   |  13  |  0.0  |\n",
            "|  3  |  56   |  14  |  0.0  |\n",
            "|  3  |  64   |  15  |  0.0  |\n",
            "|  4  |  85   |  1   | 1.258 |\n",
            "|  4  |  85   |  2   | 1.258 |\n",
            "|  4  |  62   |  3   | 0.757 |\n",
            "|  4  |   3   |  4   | 0.663 |\n",
            "|  4  |  24   |  5   | 0.596 |\n",
            "|  4  |  82   |  6   | 0.557 |\n",
            "|  4  |  82   |  7   | 0.557 |\n",
            "|  4  |  71   |  8   | 0.519 |\n",
            "|  4  |  79   |  9   | 0.51  |\n",
            "|  4  |  79   |  10  | 0.51  |\n",
            "|  4  |  30   |  11  | 0.504 |\n",
            "|  4  |  94   |  12  | 0.478 |\n",
            "|  4  |  94   |  13  | 0.478 |\n",
            "|  4  |  94   |  14  | 0.478 |\n",
            "|  4  |  26   |  15  | 0.429 |\n",
            "|  4  |  87   |  16  | 0.41  |\n",
            "|  4  |  75   |  17  | 0.41  |\n",
            "|  4  |  88   |  18  | 0.403 |\n",
            "|  4  |  88   |  19  | 0.403 |\n",
            "|  4  |  88   |  20  | 0.403 |\n",
            "|  4  |  88   |  21  | 0.403 |\n",
            "|  4  |  72   |  22  | 0.389 |\n",
            "|  4  |  72   |  23  | 0.389 |\n",
            "|  4  |  84   |  24  | 0.383 |\n",
            "|  4  |  84   |  25  | 0.383 |\n",
            "|  4  |  69   |  26  | 0.375 |\n",
            "|  4  |  68   |  27  | 0.373 |\n",
            "|  4  |  73   |  28  | 0.351 |\n",
            "|  4  |  73   |  29  | 0.351 |\n",
            "|  4  |  92   |  30  | 0.337 |\n",
            "|  4  |  76   |  31  | 0.304 |\n",
            "|  4  |  76   |  32  | 0.304 |\n",
            "|  4  |  81   |  33  | 0.289 |\n",
            "|  4  |  81   |  34  | 0.289 |\n",
            "|  4  |  70   |  35  | 0.275 |\n",
            "|  4  |  40   |  36  | 0.274 |\n",
            "|  4  |  86   |  37  | 0.206 |\n",
            "|  4  |  86   |  38  | 0.206 |\n",
            "|  4  |  93   |  39  | 0.064 |\n",
            "|  4  |  93   |  40  | 0.064 |\n",
            "|  4  |  93   |  41  | 0.064 |\n",
            "|  4  |  93   |  42  | 0.064 |\n",
            "|  4  |  96   |  43  | 0.058 |\n",
            "|  4  |  99   |  44  | 0.058 |\n",
            "|  4  |  96   |  45  | 0.058 |\n",
            "|  4  |  99   |  46  | 0.058 |\n",
            "|  4  |  89   |  47  | 0.058 |\n",
            "|  4  |  89   |  48  | 0.058 |\n",
            "|  4  |  90   |  49  | 0.058 |\n",
            "|  4  |  80   |  50  | 0.058 |\n",
            "|  4  |  91   |  51  | 0.058 |\n",
            "|  4  |  60   |  52  | 0.05  |\n",
            "|  4  |  98   |  53  | 0.048 |\n",
            "|  4  |  98   |  54  | 0.048 |\n",
            "|  4  |  98   |  55  | 0.048 |\n",
            "|  4  |  39   |  56  | 0.045 |\n",
            "|  4  |  14   |  57  | 0.044 |\n",
            "|  4  |  47   |  58  | 0.044 |\n",
            "|  4  |  59   |  59  | 0.041 |\n",
            "|  4  |  16   |  60  | 0.039 |\n",
            "|  4  |  29   |  61  | 0.034 |\n",
            "|  4  |  78   |  62  | 0.034 |\n",
            "|  4  |  74   |  63  | 0.033 |\n",
            "|  4  |  74   |  64  | 0.033 |\n",
            "|  4  |  74   |  65  | 0.033 |\n",
            "|  4  |  95   |  66  |  0.0  |\n",
            "|  4  |  17   |  67  |  0.0  |\n",
            "|  4  |  95   |  68  |  0.0  |\n",
            "|  4  |  52   |  69  |  0.0  |\n",
            "|  4  |  37   |  70  |  0.0  |\n",
            "|  4  |  25   |  71  |  0.0  |\n",
            "|  4  |  20   |  72  |  0.0  |\n",
            "|  4  |  27   |  73  |  0.0  |\n",
            "|  4  |  67   |  74  |  0.0  |\n",
            "|  4  |  97   |  75  |  0.0  |\n",
            "|  4  |  100  |  76  |  0.0  |\n",
            "|  4  |  49   |  77  |  0.0  |\n",
            "|  4  |  97   |  78  |  0.0  |\n",
            "|  4  |  65   |  79  |  0.0  |\n",
            "|  4  |  61   |  80  |  0.0  |\n",
            "|  4  |  100  |  81  |  0.0  |\n",
            "|  5  |  62   |  1   | 0.757 |\n",
            "|  5  |  24   |  2   | 0.596 |\n",
            "|  5  |  21   |  3   | 0.551 |\n",
            "|  5  |  51   |  4   | 0.476 |\n",
            "|  5  |   2   |  5   | 0.422 |\n",
            "|  5  |  34   |  6   | 0.389 |\n",
            "|  5  |   6   |  7   | 0.317 |\n",
            "|  5  |   7   |  8   |  0.3  |\n",
            "|  5  |   5   |  9   | 0.07  |\n",
            "|  5  |  55   |  10  | 0.067 |\n",
            "|  5  |  22   |  11  | 0.058 |\n",
            "|  5  |  47   |  12  | 0.044 |\n",
            "|  5  |  16   |  13  | 0.039 |\n",
            "|  5  |  28   |  14  | 0.039 |\n",
            "|  5  |  44   |  15  | 0.032 |\n",
            "|  5  |  43   |  16  |  0.0  |\n",
            "|  5  |  35   |  17  |  0.0  |\n",
            "|  5  |  25   |  18  |  0.0  |\n",
            "|  5  |  45   |  19  |  0.0  |\n",
            "|  5  |  67   |  20  |  0.0  |\n",
            "|  6  |  24   |  1   | 0.596 |\n",
            "|  6  |  51   |  2   | 0.476 |\n",
            "|  6  |  42   |  3   | 0.459 |\n",
            "|  6  |  66   |  4   | 0.43  |\n",
            "|  6  |   7   |  5   |  0.3  |\n",
            "|  6  |  40   |  6   | 0.274 |\n",
            "|  6  |   5   |  7   | 0.07  |\n",
            "|  6  |  55   |  8   | 0.067 |\n",
            "|  6  |  31   |  9   | 0.064 |\n",
            "|  6  |  10   |  10  | 0.061 |\n",
            "|  6  |  50   |  11  | 0.058 |\n",
            "|  6  |  54   |  12  | 0.048 |\n",
            "|  6  |  39   |  13  | 0.045 |\n",
            "|  6  |  56   |  14  | 0.044 |\n",
            "|  6  |  58   |  15  | 0.042 |\n",
            "|  6  |  59   |  16  | 0.041 |\n",
            "|  6  |  28   |  17  | 0.039 |\n",
            "|  6  |  41   |  18  | 0.037 |\n",
            "|  6  |  46   |  19  | 0.025 |\n",
            "|  6  |  61   |  20  |  0.0  |\n",
            "|  6  |   8   |  21  |  0.0  |\n",
            "|  6  |  35   |  22  |  0.0  |\n",
            "|  6  |   4   |  23  |  0.0  |\n",
            "|  6  |  65   |  24  |  0.0  |\n",
            "|  6  |  37   |  25  |  0.0  |\n",
            "|  6  |  64   |  26  |  0.0  |\n",
            "+-----+-------+------+-------+"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ap_score = APScorer()(y_test, pred)\n",
        "print(\"ap_score:\", ap_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdrXEew-eNrK",
        "outputId": "ef791f62-c8e6-4daa-c138-5f1a2650bc47"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ap_score: 0.1378849059560028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round_pred = np.round(pred, decimals = 0)"
      ],
      "metadata": {
        "id": "9NC5BiprDQWk"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prec_score = PScorer()(y_test, round_pred)\n",
        "print(\"precision score:\", prec_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu7zN2q9eOiE",
        "outputId": "8381f432-654e-42d8-a98b-72d7e7e9edf0"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision score: 0.07777777777777778\n"
          ]
        }
      ]
    }
  ]
}